\section{Metodología de desarrollo}
El desarrollo del Sistema de Agendamiento de Citas PQR para Electrohuila siguió un proceso iterativo y adaptativo que, aunque basado en principios establecidos de ingeniería de software, requirió múltiples ajustes y decisiones difíciles a lo largo del camino. Inicialmente, habíamos planificado una metodología más rígida, pero las realidades del proyecto nos obligaron a adoptar un enfoque más flexible. El sistema se desarrolló en tres fases principales que, lejos de ser lineales, se sobrepusieron y retroalimentaron constantemente durante los seis meses que tomó completar el proyecto.

Lo que comenzó como un proyecto aparentemente directo de agendamiento de citas rápidamente reveló complejidades que no habíamos anticipado completamente. La necesidad de integrarse con sistemas legacy de Electrohuila, las particularidades de los procesos administrativos existentes, y las expectativas de usuarios con niveles muy diversos de competencia digital nos presentaron desafíos que requirieron soluciones creativas e iteraciones constantes.

\subsection{Fase 1: Análisis y Diseño del Sistema}
Esta etapa inicial, que originalmente estimamos tomaría seis semanas, terminó extendiéndose a casi diez. No porque no supiéramos lo que hacíamos, sino porque cada conversación con los stakeholders de Electrohuila revelaba nuevos matices sobre cómo funcionaban realmente sus procesos. Las bases arquitectónicas y funcionales del proyecto tomaron forma a través de un proceso de descubrimiento continuo más que de una especificación inicial completa.

\begin{itemize}
    \item \textbf{Levantamiento de requerimientos:} Las primeras sesiones de trabajo con los stakeholders de Electrohuila fueron reveladoras, aunque no siempre en la dirección que esperábamos. Comenzamos con reuniones formales estructuradas donde discutíamos procesos actuales de agendamiento de citas PQR, pero pronto descubrimos que existía una considerable distancia entre los procesos "oficiales" y cómo las cosas realmente funcionaban día a día.

    Por ejemplo, durante nuestra tercera reunión, una supervisora del área de servicio al cliente mencionó casualmente que los empleados frecuentemente hacían "arreglos especiales" para ciertos ciudadanos que no podían cumplir con los horarios estándar. Este tipo de flexibilidad informal no estaba documentada en ningún manual de procedimientos, pero era crucial para el servicio que Electrohuila brindaba a comunidades rurales. Tuvimos que regresar varias veces a reformular nuestros casos de uso para capturar estas prácticas.

    Documentamos casos de uso para dos tipos principales de usuarios: ciudadanos que necesitaban agendar, consultar o cancelar citas, y administradores que gestionaban empleados, configuraban horarios, asignaban permisos y administraban múltiples sucursales. Sin embargo, las categorías reales resultaron más difusas. Descubrimos que necesitábamos roles intermedios, como supervisores de sucursal que no eran administradores completos pero necesitaban más permisos que un empleado regular. Estas complejidades organizacionales nos llevaron a rediseñar nuestro sistema de permisos tres veces antes de llegar a una solución que todos consideraran adecuada.

    \item \textbf{Diseño de base de datos:} El modelo de datos fue probablemente el componente que más iteraciones requirió. Inicialmente, creamos un diseño que nos parecía elegante y limpio, siguiendo estrictamente los principios de normalización hasta la tercera forma normal (3NF). Utilizamos Draw.io para el Modelo Entidad-Relación, y estábamos bastante orgullosos del resultado. El problema surgió cuando lo presentamos al equipo de TI de Electrohuila.

    Resultó que Oracle Database, que Electrohuila había usado durante años para otros sistemas, tenía ciertas peculiaridades en su configuración particular. Además, había expectativas sobre convenciones de nombres que no habíamos considerado inicialmente. Pasamos una semana completa refactorizando nombres de tablas y campos para alinearnos con los estándares existentes de Electrohuila. No era técnicamente necesario, pero facilitaría significativamente la adopción y el mantenimiento futuro.

    El modelo definió entidades principales: Usuario, Empleado, Cita, Sucursal, Rol, Permiso, DiaFestivo, y sus relaciones (uno a muchos, muchos a muchos). Pero cada entidad tiene su historia. La entidad DiaFestivo, por ejemplo, no estaba en nuestro diseño original. La agregamos después de que un empleado nos explicara que Electrohuila celebraba días festivos regionales adicionales que variaban según la sucursal, algo que ningún sistema estándar de festivos podía manejar automáticamente.

    Establecimos restricciones de integridad referencial con cuidado, pero tuvimos que balancear pureza teórica con practicidad. En un caso particular, debatimos intensamente si las citas canceladas deberían eliminarse mediante "soft delete" o mantenerse con un estado de "cancelada". Inicialmente optamos por soft delete por razones de auditoría, pero luego descubrimos que esto complicaba enormemente las consultas de disponibilidad. Después de varios experimentos con índices y vistas materializadas, encontramos una solución intermedia usando estados y triggers para auditoría que satisfacía ambas necesidades sin sacrificar rendimiento.

    \item \textbf{Diseño de interfaces de usuario:} Los mockups iniciales que creamos en Figma eran, en retrospectiva, demasiado ambiciosos en términos de funcionalidad y demasiado genéricos en términos de contexto. Habíamos diseñado interfaces que lucían modernas y seguían todas las heurísticas de usabilidad de Nielsen, pero no reflejaban realmente las necesidades específicas de los usuarios de Electrohuila.

    El portal administrativo web pasó por cinco iteraciones mayores. La primera versión priorizaba estética sobre funcionalidad, con animaciones elegantes y transiciones suaves. Cuando la mostramos a los administradores reales, su reacción fue educativa: no les importaban las animaciones, querían poder procesar solicitudes rápidamente. Una administradora nos dijo francamente: "Esto se ve bonito, pero yo proceso cien citas al día. Necesito ver toda la información de un vistazo y hacer cambios con el menor número de clics posible." Ese comentario reorientó completamente nuestro enfoque hacia eficiencia para tareas repetitivas.

    La aplicación móvil presentó desafíos diferentes. Inicialmente asumimos que los ciudadanos querrían muchas opciones y filtros avanzados. Las pruebas de usuario con ciudadanos reales en las oficinas de Electrohuila demostraron lo contrario. Vimos a personas mayores confundirse con menús de múltiples niveles, y a usuarios rurales con conexiones de datos limitadas frustrarse con interfaces que requerían muchas llamadas al servidor. Simplificamos radicalmente el diseño, reduciendo cada flujo al mínimo número de pasos necesarios. Lo que perdimos en flexibilidad lo ganamos en adopción real.

    Un momento crucial vino cuando probamos prototipos con ciudadanos de diferentes niveles de alfabetización digital. Una usuaria de aproximadamente sesenta años nos mostró cómo ella normalmente "lee" aplicaciones: ignorando texto y tocando cualquier cosa que parezca un botón hasta que algo funcione. Ese día aprendimos que nuestros cuidadosamente escritos textos de ayuda probablemente serían ignorados. Necesitábamos interfaces que fueran intuitivas incluso para usuarios que no leen las instrucciones.

    \item \textbf{Definición de arquitectura:} La arquitectura fue uno de los aspectos donde más tuvimos que balancear idealismo técnico con pragmatismo. Habíamos leído extensivamente sobre Clean Architecture y estábamos convencidos de que era el camino correcto. El desafío fue implementarla sin crear una sobrecarga innecesaria de complejidad para un equipo que eventualmente tendría que mantener el sistema.

    Establecimos una arquitectura de tres capas basada en Clean Architecture para el backend, pero con adaptaciones pragmáticas. La estructura incluye: (1) Capa de Dominio con entidades y reglas de negocio core, donde colocamos toda la lógica que es verdaderamente fundamental e independiente de tecnología; (2) Capa de Aplicación con casos de uso y DTOs, que orquesta la lógica de dominio y define las interfaces que el mundo exterior necesita; (3) Capa de Infraestructura con implementaciones concretas de repositorios y servicios externos, donde viven los detalles de Oracle Database, SignalR, y otras tecnologías específicas; (4) Capa de API con controllers y middleware, que maneja HTTP y todo lo relacionado con REST.

    La decisión de usar Clean Architecture no fue unánime en el equipo. Un desarrollador argumentaba que era "overengineering" para un proyecto de este tamaño. Tuvimos varias sesiones donde debatimos este punto. Al final, lo que nos convenció fue pensar en el futuro: Electrohuila quería eventualmente integrar este sistema con otros servicios, y Clean Architecture nos daría la flexibilidad para hacerlo sin reescribir todo. Resultó ser la decisión correcta, porque seis semanas después del inicio del desarrollo, Electrohuila nos pidió integrar con un sistema de notificaciones SMS que no había sido parte del requerimiento original. Gracias a nuestra arquitectura, pudimos agregarlo sin modificar la lógica de negocio core.

    Para el frontend móvil seleccionamos el patrón MVVM, que nos daba clara separación entre presentación, lógica de presentación y modelo de datos. Esta decisión fue más straightforward que la arquitectura del backend, principalmente porque .NET MAUI prácticamente empuja hacia MVVM de manera natural. Para el frontend web optamos por una arquitectura de componentes con gestión de estado centralizada mediante Zustand en lugar de Redux. Esta fue otra decisión pragmática: Redux nos parecía demasiado boilerplate-heavy para nuestras necesidades, y Zustand ofrecía simplicidad sin sacrificar capacidad.

    \item \textbf{Selección del stack tecnológico:} Si hay una decisión que nos quitó más el sueño en las primeras semanas, fue la selección del stack tecnológico. Teníamos múltiples opciones viables, y cada una tenía sus defensores apasionados en el equipo. Realizamos un análisis comparativo considerando madurez del ecosistema, soporte empresarial, disponibilidad de documentación, facilidad de mantenimiento futuro, y compatibilidad con Oracle Database que era un requerimiento no negociable.

    Para el backend, la decisión entre .NET Core y Node.js fue particularmente contenciosa. Hicimos prototipos de spike con ambas tecnologías durante una semana. Node.js tenía la ventaja de JavaScript en todo el stack, lo cual era atractivo. Pero .NET 9 ganó por varias razones pragmáticas: su rendimiento era notablemente mejor en nuestras pruebas, el soporte para Oracle Database era más maduro y robusto, y el equipo de TI de Electrohuila ya tenía experiencia con .NET. El último punto resultó ser más importante de lo que inicialmente pensamos, porque significaba que Electrohuila podría eventualmente mantener el sistema con sus propios recursos.

    Next.js 15 para el frontend web fue una elección más fácil, principalmente porque la capacidad de Server-Side Rendering nos permitiría optimización para usuarios con conexiones lentas, algo común en zonas rurales de Huila. Además, la optimización automática de imágenes y code splitting que Next.js ofrece out-of-the-box nos ahorraría semanas de trabajo de optimización manual.

    La decisión de usar .NET MAUI para la aplicación móvil, sin embargo, fue un gamble calculado. MAUI era relativamente nuevo en ese momento, y había opciones más maduras como React Native o Flutter. Pero la capacidad de reutilizar código C\# y compartir modelos con el backend era demasiado atractiva. También consideramos que la mayoría de ciudadanos en Huila usan Android, pero había suficientes usuarios de iOS para que una solución verdaderamente multiplataforma valiera la pena. Tuvimos algunos problemas con MAUI en las primeras semanas, particularmente con la renderización de listas largas en Android, pero eventualmente encontramos soluciones y workarounds.

    SignalR para comunicación en tiempo real fue quizás la decisión más straightforward, principalmente porque se integra nativamente con .NET y cumplía perfectamente nuestros requerimientos de notificaciones push. Consideramos brevemente alternativas como Socket.IO, pero la integración perfecta con nuestro backend .NET hizo que SignalR fuera la elección obvia.
\end{itemize}

La \cref{fig:inicio_proyecto} presenta el flujo completo del proyecto desde su inicio hasta las fases de implementación y pruebas, aunque en la práctica, estas fases se sobrelaparon más de lo que el diagrama sugiere.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{graphics/inicio_proyecto.png}
    \caption{Flujo del proyecto desde análisis hasta implementación}
    \label{fig:inicio_proyecto}
\end{figure}

\subsection{Fase 2: Implementación del Sistema}
Esta fase fue donde el diseño cuidadoso de la Fase 1 se encontró con la realidad del código y, como suele suceder, donde descubrimos que muchas cosas que parecían simples en papel eran sorprendentemente complejas en la práctica. El desarrollo completo de los tres componentes principales tomó aproximadamente doce semanas, aunque hubo períodos donde estábamos trabajando en los tres componentes simultáneamente, lo cual creó sus propios desafíos de coordinación.

\begin{itemize}
    \item \textbf{Implementación del backend API:} El desarrollo del API RESTful con .NET 9 comenzó con optimismo, pero rápidamente nos encontramos con complejidades inesperadas. Seguir Clean Architecture significaba mucho código de infraestructura antes de poder escribir funcionalidad real. Durante las primeras dos semanas, sentíamos que estábamos escribiendo mucho código sin ver mucho progreso visible, lo cual era frustrante pero necesario.

    Creamos controllers para cada entidad del sistema (Citas, Empleados, Usuarios, Sucursales, Roles, Permisos, DíasFestivos) con endpoints CRUD completos. La implementación de los controllers de Citas fue particularmente desafiante porque tenía lógica compleja de validación de disponibilidad. Inicialmente pusimos esta lógica directamente en el controller, lo cual funcionaba pero violaba nuestros principios arquitectónicos. Refactorizamos para mover la lógica a servicios de dominio, lo cual tomó tres días pero dejó el código mucho más limpio y testeable.

    Entity Framework Core con Oracle Provider nos dio algunos dolores de cabeza. La documentación para Oracle Provider es menos completa que para SQL Server, y nos encontramos regularmente en StackOverflow buscando soluciones a problemas específicos. Un problema particularmente frustrante involucró secuencias de Oracle para IDs auto-incrementales. La convención de Entity Framework no funcionaba correctamente con la configuración existente de Oracle en Electrohuila, y pasamos dos días completos debuggeando antes de encontrar una solución que involucraba configuración manual de secuencias en el DbContext.

    Las migraciones de Entity Framework también presentaron desafíos. Inicialmente generábamos migraciones libremente a medida que evolucionaba el modelo, pero esto creó un historial de migraciones confuso con muchos cambios pequeños. A mitad del proyecto, tuvimos que consolidar varias migraciones en una sola para mantener la cordura. Aprendimos a ser más deliberados sobre cuándo crear nuevas migraciones.

    Los servicios de lógica de negocio para validaciones complejas fueron donde pasamos la mayor parte del tiempo. La validación de disponibilidad de citas parecía simple conceptualmente: verificar si hay un slot de tiempo libre. En realidad, tenía que considerar horarios de empleados, días festivos (tanto nacionales como específicos de sucursal), citas ya agendadas, tiempo de buffer entre citas, horarios especiales de sucursales, y excepciones para citas de emergencia. El código para esto creció a más de doscientas líneas con múltiples casos edge que descubrimos solo mediante pruebas exhaustivas.

    La prevención de conflictos de horarios resultó especialmente complicada con múltiples usuarios concurrentes. Nuestro primer intento usaba validación optimista, pero descubrimos durante pruebas de carga que dos usuarios podían ocasionalmente agendar la misma cita en una condición de carrera. Tuvimos que implementar bloqueo pesimista para slots de tiempo durante el proceso de agendamiento, lo cual afectó el rendimiento pero garantizó consistencia. Balancear rendimiento y corrección fue un tema recurrente.

    Implementamos autenticación basada en JWT con roles y permisos granulares. Aquí nos beneficiamos de seguir patrones establecidos, aunque tuvimos que personalizar bastante el sistema de permisos para manejar los requerimientos específicos de Electrohuila. El middleware de autorización fue particularmente divertido de escribir porque nos permitió usar atributos declarativos en controllers, haciendo el código de autorización muy limpio y legible.

    La configuración de SignalR Hubs para notificaciones en tiempo real fue más fácil de lo anticipado, principalmente porque la documentación de Microsoft para SignalR es excelente. Implementamos Hubs para enviar notificaciones sobre cambios de estado de citas, nuevas asignaciones, y alertas administrativas. Un desafío interesante fue decidir qué enviar por SignalR versus qué podía esperar a polling regular. Enviábamos demasiadas notificaciones inicialmente, lo cual sobrecargaba el servidor y el cliente con actualizaciones triviales. Refinamos esto para enviar solo cambios genuinamente importantes.

    \item \textbf{Desarrollo del portal administrativo web:} El frontend web con Next.js 15 fue un cambio refrescante después de trabajar en el backend, aunque trajo sus propios desafíos. Decidimos usar el nuevo App Router de Next.js en lugar del Pages Router tradicional, lo cual en retrospectiva fue algo arriesgado dado que App Router era relativamente nuevo. Tuvimos que desaprender algunos patrones y aprender nuevas formas de hacer cosas que antes eran simples.

    Server Components nos confundieron inicialmente. La distinción entre Server Components y Client Components no siempre era obvia, y cometimos errores al intentar usar hooks de React en Server Components, lo cual obviamente no funciona. Pasamos varios días aprendiendo los patrones correctos. Una vez que los entendimos, sin embargo, los beneficios de rendimiento eran notables, especialmente para data fetching.

    Desarrollamos componentes React con TypeScript, lo cual agregó seguridad de tipos pero también verbosidad. Hubo debate en el equipo sobre si TypeScript valía el overhead. Yo era escéptico inicialmente, pero después de que TypeScript nos salvó de varios bugs sutiles relacionados con tipos de datos incorrectos del API, me convertí en creyente. El autocompletado en el IDE también mejoró dramáticamente la velocidad de desarrollo una vez que teníamos tipos bien definidos.

    Para gestión de estado global, seleccionamos Zustand sobre Redux o Context API. Esta decisión la tomamos después de que intentar configurar Redux para un caso de uso simple nos tomó dos horas y resultó en cientos de líneas de boilerplate. Zustand nos permitió lograr lo mismo en menos de veinte líneas. No tiene el ecosistema masivo de Redux, pero para nuestras necesidades era más que suficiente. Usamos Zustand principalmente para información de autenticación, datos de usuario actual, y estado de notificaciones.

    La integración de Tailwind CSS con componentes de shadcn/ui fue inicialmente controversial en el equipo. Un desarrollador odiaba la idea de utility classes en el markup, argumentando que violaba separación de concerns. Otro amaba la velocidad de desarrollo que Tailwind permitía. Hicimos un compromiso: usaríamos Tailwind pero extraeríamos componentes reutilizables activamente para evitar repetición de clases. Shadcn/ui nos dio componentes base bien diseñados que podíamos personalizar, ahorrando semanas de trabajo de diseño de componentes desde cero.

    Los formularios con validación fueron sorprendentemente complejos. Usamos React Hook Form con Zod para validación de esquemas, lo cual funcionaba bien pero requería definir esquemas de validación separados que a veces se salían de sincronización con los tipos de TypeScript. Eventualmente configuramos generación automática de esquemas Zod desde tipos TypeScript usando una librería helper, lo cual redujo duplicación.

    Las tablas con paginación, ordenamiento y filtrado consumieron más tiempo del esperado. Construimos nuestro propio componente de tabla inicialmente, pero después de dos semanas teníamos algo que funcionaba pero era buggy y difícil de mantener. Finalmente admitimos la derrota y usamos TanStack Table (anteriormente React Table), que nos dio toda la funcionalidad que necesitábamos con mucho menos código custom. A veces es mejor no reinventar la rueda.

    Los dashboards con visualización de métricas clave fueron divertidos de implementar. Usamos Recharts para gráficos, que es suficientemente flexible sin ser abrumadoramente complejo. Un desafío fue decidir qué métricas mostrar. Los administradores de Electrohuila querían ver todo, lo cual habría resultado en un dashboard sobrecargado. Tuvimos varias sesiones de diseño para reducir a las métricas realmente importantes: citas pendientes, tasa de cancelación, empleados disponibles, y distribución de citas por tipo de servicio.

    La implementación del cliente SignalR para recibir notificaciones en tiempo real y actualizar la interfaz automáticamente fue técnicamente straightforward pero requirió pensamiento cuidadoso sobre UX. Las notificaciones que aparecen sin acción del usuario pueden ser sorprendentes o molestas. Implementamos diferentes niveles de intrusividad: notificaciones críticas que requerían acción mostraban modales, notificaciones importantes aparecían como toasts, y notificaciones informativas solo actualizaban badges de conteo. Este sistema evolucionó basado en feedback de usuarios beta.

    \item \textbf{Desarrollo de la aplicación móvil:} La aplicación móvil con .NET MAUI fue probablemente el componente más desafiante técnicamente, principalmente porque MAUI todavía tenía rough edges como tecnología relativamente nueva. Encontramos bugs en el framework mismo varias veces, lo cual requirió workarounds creativos o, en algunos casos, reportar issues al equipo de MAUI y esperar fixes.

    Implementamos el patrón MVVM rigurosamente usando CommunityToolkit.MVVM, que genera código boilerplate automáticamente mediante source generators. Esto funcionaba mágicamente cuando funcionaba, pero cuando fallaba, los errores eran crípticos. Los source generators son código que genera código en compile time, lo cual significa que los errores pueden ser difíciles de debuggear. Aprendimos a limpiar la solución y rebuildar frecuentemente cuando cosas extrañas sucedían.

    Creamos ViewModels para cada pantalla con Commands para acciones de usuario, ObservableProperties para binding de datos, y lógica de navegación. El desafío principal fue decidir cuánta lógica poner en ViewModels versus servicios compartidos. Inicialmente pusimos demasiado en ViewModels, lo cual resultó en duplicación entre pantallas similares. Refactorizamos para extraer servicios compartidos para operaciones comunes como fetching de datos y validación.

    La implementación de HttpClient para consumo del API REST fue straightforward en concepto pero tenía detalles molestos. El manejo de tokens JWT requería agregar headers de autorización a cada request, lo cual hicimos mediante un DelegatingHandler custom que interceptaba requests y agregaba el token automáticamente. La gestión de errores de red fue particularmente importante porque la aplicación móvil podía usarse en áreas con conectividad pobre. Implementamos retry logic con backoff exponencial para requests fallidos, lo cual mejoró significativamente la experiencia en conexiones inestables.

    SecureStorage para almacenamiento seguro de credenciales y tokens funcionaba diferente en Android versus iOS, lo cual nos causó dolores de cabeza. En Android usaba el KeyStore, mientras que en iOS usaba el Keychain. Las APIs eran similares pero no idénticas, y tuvimos bugs específicos de plataforma que solo descubrimos mediante testing extensivo en dispositivos físicos. El emulador frecuentemente comportaba diferente que dispositivos reales, especialmente para funcionalidad de seguridad.

    Las pantallas que desarrollamos (búsqueda de citas disponibles, agendamiento, consulta de citas existentes, cancelación con confirmación) pasaron por múltiples iteraciones de diseño. La pantalla de búsqueda de citas disponibles fue particularmente desafiante porque necesitaba mostrar un calendario de disponibilidad sin abrumar al usuario con información. Experimentamos con varios diseños antes de llegar a uno que funcionara bien tanto en pantallas pequeñas como grandes.

    Un problema inesperado fue el rendimiento de listas largas en Android. Cuando un usuario tenía muchas citas históricas, la lista se volvía lenta y janky. MAUI usa virtualización para listas, pero no estaba funcionando correctamente en nuestro caso. Eventualmente descubrimos que estábamos binding demasiada data compleja en cada celda de la lista. Simplificamos los bindings y agregamos paginación, lo cual resolvió el problema.

    \item \textbf{Integración y comunicación entre componentes:} Una vez que teníamos los tres componentes parcialmente funcionales, el trabajo real de integración comenzó. En teoría, dado que todos consumían y producían JSON y usaban el mismo API, todo debería funcionar perfectamente. En práctica, hubo fricción en cada punto de contacto.

    Implementamos comunicación mediante APIs REST con formato JSON, lo cual es estándar, pero los detalles eran importantes. Por ejemplo, el formato de fechas causó problemas recurrentes. .NET serializa fechas en un formato, JavaScript espera otro, y Oracle tiene sus propias ideas sobre formatos de fecha. Eventualmente estandarizamos en ISO 8601 para todo, pero no antes de pasar dos días debuggeando por qué las citas aparecían con fechas incorrectas en la aplicación móvil.

    Desarrollamos DTOs (Data Transfer Objects) para transferencia de datos entre capas, aplicando el principio de mapeo entre entidades de dominio y objetos de transferencia. Escribimos mucho código de mapeo tedioso hasta que descubrimos AutoMapper, que automatizaba la mayoría de nuestro mapeo. Sin embargo, AutoMapper tenía su propia curva de aprendizaje, y a veces el mapeo automático hacía cosas inesperadas que eran difíciles de debuggear. Usamos AutoMapper para casos simples pero mantuvimos mapeo manual para casos complejos.

    La configuración de CORS en el backend para permitir peticiones desde el frontend web y la aplicación móvil fue algo que olvidamos inicialmente, resultando en errores confusos cuando el frontend intentaba llamar al API. Una vez que recordamos configurar CORS correctamente, funcionó bien, aunque tuvimos que ser cuidadosos sobre qué orígenes permitíamos en producción versus desarrollo.

    El manejo centralizado de errores con códigos HTTP apropiados y mensajes descriptivos evolucionó significativamente durante el desarrollo. Inicialmente, nuestros mensajes de error eran demasiado técnicos y en inglés. Los usuarios de Electrohuila necesitaban mensajes en español y en lenguaje que tuviera sentido para no-desarrolladores. Creamos un sistema de códigos de error con mensajes localizados, lo cual mejoró dramáticamente la experiencia cuando algo salía mal.

    SignalR para comunicación bidireccional requirió configuración cuidadosa de grupos para notificaciones dirigidas. No queríamos que todos los usuarios recibieran todas las notificaciones, entonces implementamos grupos basados en roles y sucursales. La reconexión automática en caso de pérdida de conexión funcionaba out-of-the-box en la web, pero requirió lógica custom en la aplicación móvil para manejar transiciones de background a foreground correctamente.
\end{itemize}

La \cref{fig:ciclo_desarrollo} ilustra el ciclo iterativo de desarrollo, mostrando la interacción continua entre las diferentes etapas del proyecto. En la práctica, este ciclo se ejecutaba casi diariamente, con descubrimientos en implementación frecuentemente requeriendo ajustes en diseño.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\textwidth]{graphics/ciclo_desarrollo.png}
    \caption{Ciclo iterativo de desarrollo del sistema}
    \label{fig:ciclo_desarrollo}
\end{figure}

\subsection{Fase 3: Pruebas y Validación}
La fase de pruebas reveló, como siempre, que muchas cosas que pensábamos funcionaban perfectamente tenían problemas sutiles. Originalmente habíamos planeado dos semanas para pruebas, pero terminamos necesitando casi cuatro. No porque el código fuera particularmente malo, sino porque testing exhaustivo simplemente toma tiempo, y cada bug encontrado requiere tiempo para corregir y re-testear.

\begin{itemize}
    \item \textbf{Pruebas unitarias:} Admitimos como equipo que no habíamos escrito suficientes pruebas unitarias durante el desarrollo. La presión por entregar funcionalidad visible había resultado en menos cobertura de pruebas de la ideal. Durante esta fase, nos enfocamos en desarrollar pruebas para la lógica de negocio crítica usando xUnit para .NET.

    Las pruebas de servicios de validación de disponibilidad fueron particularmente importantes dado lo compleja que era esa lógica. Escribir estas pruebas actuamente descubrió bugs que no habíamos notado durante desarrollo y pruebas manuales. Por ejemplo, había un edge case donde si una cita se agendaba exactamente a medianoche en un día festivo, el sistema la aceptaba incorrectamente. Solo lo descubrimos mediante pruebas exhaustivas de casos límite.

    Aplicamos el patrón AAA (Arrange-Act-Assert) para estructurar las pruebas de manera clara. Este patrón ayuda a mantener las pruebas legibles, lo cual es crucial porque las pruebas necesitan mantenerse junto con el código que prueban. Pruebas confusas son pruebas que eventualmente se ignoran o eliminan.

    El cálculo de horarios disponibles tenía lógica compleja que involucraba zona horaria, horarios de empleados, y múltiples configuraciones. Las pruebas para esto fueron tedias de escribir porque requerían setup de mucho estado, pero valieron la pena. Refactorizamos el código varias veces basados en dificultades que encontramos al intentar testearlo. Código que es difícil de testear frecuentemente es código que tiene problemas de diseño.

    Alcanzamos una cobertura de código superior al 70 por ciento en componentes críticos, lo cual consideramos adecuado aunque no perfecto. Algunos desarrolladores argumentaban por 90+ por ciento de cobertura, pero decidimos que más allá de cierto punto, estábamos escribiendo pruebas de valor marginal. El 70 por ciento en componentes críticos más pruebas de integración nos daba confianza razonable.

    \item \textbf{Pruebas de integración:} Estas pruebas fueron donde descubrimos la mayoría de los problemas reales. Las pruebas unitarias prueban componentes aislados, pero muchos bugs aparecen solo cuando componentes interactúan. Realizamos pruebas para verificar la correcta comunicación entre todos los componentes del sistema.

    Probamos el flujo completo de agendamiento de citas desde la aplicación móvil hasta la persistencia en Oracle Database. Este flujo involucraba la aplicación móvil enviando un request HTTP al API, el API validando permisos y disponibilidad, Entity Framework escribiendo a Oracle, y finalmente SignalR notificando al portal web. Había muchos puntos donde cosas podían fallar, y fallar lo hicieron durante testing.

    Un problema particularmente insidioso involucraba transacciones de base de datos. Ocasionalmente, una cita se creaba en la base de datos pero la notificación SignalR fallaba, dejando el sistema en un estado inconsistente donde la cita existía pero nadie era notificado. Implementamos un patrón de outbox para garantizar que notificaciones eventualmente se enviaran incluso si el envío inicial fallaba.

    Validamos la sincronización de notificaciones en tiempo real mediante SignalR creando escenarios donde múltiples usuarios interactuaban simultáneamente. Las condiciones de carrera aparecen solo bajo carga concurrente, entonces tuvimos que ser creativos en crear situaciones que forzaran estos escenarios. Automatizar estas pruebas fue difícil, entonces muchas fueron manuales, lo cual las hacía tediosas pero necesarias.

    Verificamos el comportamiento del sistema ante fallos de componentes externos simulando fallos de red, base de datos caída, y otros escenarios de desastre. El sistema no siempre se comportaba gracefully en estos escenarios. Tuvimos que agregar mucho código de manejo de errores y retry logic que no habíamos considerado inicialmente. Es fácil olvidar que las cosas fallan hasta que las pruebas forzadamente las hacen fallar.

    \item \textbf{Pruebas de rendimiento:} Aquí es donde las cosas se pusieron interesantes y un poco estresantes. Evaluamos el rendimiento del sistema usando Apache JMeter para simulación de carga. Nunca habíamos usado JMeter antes, entonces hubo una curva de aprendizaje solo en configurar las pruebas correctamente.

    Simulamos múltiples usuarios concurrentes agendando citas simultáneamente, comenzando con diez usuarios, luego cincuenta, luego cien. El sistema manejaba diez usuarios perfectamente. Con cincuenta, comenzamos a ver degradación de rendimiento. Con cien, esencialmente colapsaba, con tiempos de respuesta de más de treinta segundos. Esto era inaceptable.

    Pasamos una semana completa perfilando y optimizando. Medimos tiempos de respuesta del API, throughput, y uso de recursos. El profiler reveló que pasábamos la mayoría del tiempo en queries de base de datos. Identificamos consultas SQL lentas, particularmente las que verificaban disponibilidad de citas, que hacían scans de tabla completa en lugar de usar índices.

    Optimizamos mediante índices adicionales en columnas frecuentemente consultadas como fecha de cita, ID de empleado, y estado de cita. También refactorizamos queries complejas que usaban subqueries anidadas a joins más eficientes. Una query particularmente problemática que tomaba dos segundos la redujimos a cincuenta milisegundos mediante refactorización y un índice compuesto.

    Después de optimizaciones, el sistema manejaba cien usuarios concurrentes con tiempos de respuesta aceptables (menos de un segundo para la mayoría de operaciones). No era perfecto, pero era adecuado para las necesidades de Electrohuila, que no esperaba picos de más de treinta usuarios simultáneos en operación normal. Optimización prematura es la raíz de todo mal, pero optimización basada en mediciones reales es ingeniería responsable.

    \item \textbf{Pruebas de usabilidad:} Estas fueron probablemente las pruebas más reveladoras y humillantes. Realizamos sesiones con usuarios reales, tanto administradores de Electrohuila como ciudadanos, para evaluar la usabilidad de las interfaces. Ver a usuarios reales interactuar con software que has construido es una experiencia educativa que ningún curso puede replicar.

    Los administradores generalmente entendían las interfaces rápidamente, aunque encontraron varios flujos confusos. Un administrador pasó cinco minutos buscando cómo cancelar una cita porque el botón no estaba donde él esperaba. Este tipo de feedback es invaluable porque muestra que incluso cuando la funcionalidad existe, si los usuarios no pueden encontrarla, efectivamente no existe.

    Los ciudadanos usando la aplicación móvil nos dieron el feedback más brutal y más útil. Vimos a usuarios confundirse en pasos que nos parecían obvios. Una señora tocó el logo de Electrohuila repetidamente, esperando que la llevara al inicio, pero no hacía nada. Agregamos navegación ahí inmediatamente. Otro usuario intentó seleccionar una fecha tocando números en lugar del date picker que habíamos provisto. Estos momentos te enseñan humildad sobre tus asunciones de diseño.

    Recopilamos observaciones sobre flujos confusos, elementos poco intuitivos, y sugerencias de mejora. Muchas sugerencias eran conflictivas (algunos usuarios querían más opciones, otros querían menos), lo cual requería juicio sobre qué feedback seguir. Implementamos ajustes en las interfaces basados en el feedback más consistente. Por ejemplo, varios usuarios mencionaron que los botones eran demasiado pequeños, entonces aumentamos el tamaño de toque para todos los elementos interactivos.

    Una mejora significativa vino de observar que los usuarios frecuentemente no sabían si una acción había sido exitosa. Agregamos confirmaciones visuales más prominentes después de acciones importantes, con animaciones breves y mensajes claros. "Su cita ha sido agendada exitosamente" con un ícono de checkmark verde funcionaba mucho mejor que nuestro feedback anterior sutil.

    \item \textbf{Pruebas de seguridad:} Realizamos pruebas de seguridad básicas, reconociendo que no éramos expertos en seguridad pero que al menos podíamos identificar vulnerabilidades comunes. Usamos OWASP Top 10 como guía para qué buscar.

    Validamos la correcta implementación de autenticación y autorización intentando acceder a recursos sin tokens válidos, con tokens expirados, y con tokens de usuarios que no deberían tener permisos. Encontramos algunos endpoints que accidentalmente no verificaban permisos correctamente, lo cual habría sido un problema serio en producción. Estos bugs eran fáciles de corregir una vez encontrados, pero habrían sido difíciles de descubrir sin testing enfocado en seguridad.

    Verificamos la protección contra inyección SQL mediante el uso de consultas parametrizadas en Entity Framework. Entity Framework hace esto automáticamente, lo cual es bueno, pero verificamos que no habíamos bypass
eado esta protección con queries SQL raw en ningún lugar. Encontramos un caso donde habíamos usado una query raw para optimización, y aunque no era vulnerable en el código actual, podría haberlo sido con cambios futuros. Refactorizamos para usar LINQ.

    Probamos la resistencia contra Cross-Site Scripting (XSS) intentando inyectar scripts en campos de entrada. Next.js y React escapan contenido automáticamente, lo cual nos protegía en la mayoría de casos, pero encontramos un lugar donde estábamos usando dangerouslySetInnerHTML para renderear HTML. Aunque el contenido venía de nuestra propia base de datos, era mejor sanitizarlo. Agregamos sanitización usando DOMPurify.

    La protección contra Cross-Site Request Forgery (CSRF) la validamos verificando que todos los endpoints que modificaban estado requerían tokens CSRF apropiados. Next.js tiene protección CSRF incorporada para forms, pero tuvimos que configurarla correctamente para requests AJAX.

    Validamos el almacenamiento seguro de contraseñas verificando que estábamos usando hashing con bcrypt con un factor de costo apropiado. Inicialmente habíamos usado un factor de costo bajo para velocidad en desarrollo, pero lo aumentamos para producción. También verificamos que no estábamos logging contraseñas en ningún lado, lo cual suena obvio pero es un error sorprendentemente común.
\end{itemize}

Esta metodología estructurada en tres fases, aunque adaptada y ajustada continuamente basada en realidades del proyecto, nos permitió desarrollar un sistema que cumple con los requerimientos empresariales de Electrohuila. No fue un proceso perfecto (ningún desarrollo real lo es), pero mediante iteración constante, comunicación abierta sobre problemas, y disposición para ajustar planes cuando era necesario, creamos un sistema robusto que las personas realmente querían usar.

Mirando hacia atrás, si tuviéramos que hacer el proyecto nuevamente, hay cosas que haríamos diferente. Habríamos invertido más tiempo en pruebas de usabilidad tempranas en lugar de esperar hasta que el sistema estuviera mayormente completo. Habríamos sido más disciplinados sobre escribir pruebas unitarias durante desarrollo en lugar de retroactivamente. Habríamos aprendido JMeter antes para poder hacer pruebas de rendimiento más temprano. Pero estos son aprendizajes que solo vienen de la experiencia, y el proyecto nos dio abundante experiencia en ingeniería de software moderna aplicada a problemas reales.
